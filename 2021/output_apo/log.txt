Fitting 4 folds for each of 162 candidates, totalling 648 fits
XgBoost Best parameter: {'eval_metric': 'rmse', 'gamma': 0.9, 'importance_type': 'gain', 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 5000, 'objective': 'binary:logistic', 'subsample': 0.9}
----XGBoost train start----
[0]	validation_0-rmse:0.49685
[10]	validation_0-rmse:0.49305
[20]	validation_0-rmse:0.49627
[23]	validation_0-rmse:0.49942
fit fold=1 0.032[s]
Fold 1 F1: 51.28205128205129
[0]	validation_0-rmse:0.49629
[10]	validation_0-rmse:0.48377
[20]	validation_0-rmse:0.50611
[21]	validation_0-rmse:0.50657
fit fold=2 0.025[s]
Fold 2 F1: 51.28205128205129
[0]	validation_0-rmse:0.50084
[10]	validation_0-rmse:0.47244
[20]	validation_0-rmse:0.46484
[30]	validation_0-rmse:0.45413
[40]	validation_0-rmse:0.45662
[42]	validation_0-rmse:0.45703
fit fold=3 0.029[s]
Fold 3 F1: 68.57142857142857
[0]	validation_0-rmse:0.50089
[10]	validation_0-rmse:0.51406
[11]	validation_0-rmse:0.51617
fit fold=4 0.010[s]
Fold 4 F1: 34.285714285714285
FINISHED | Whole XGBOOST F1: 51.3514

Fitting 4 folds for each of 540 candidates, totalling 2160 fits
LightGBM Best parameter: {'colsample_bytree': 0.9, 'importance_type': 'gain', 'learning_rate': 0.01, 'max_depth': 3, 'metrics': 'l2', 'n_estimators': 3000, 'num_leaves': 3, 'objective': 'binary'}
----LightGBM train start----
Training until validation scores don't improve for 10 rounds
[10]	valid_0's l2: 0.247934
Early stopping, best iteration is:
[3]	valid_0's l2: 0.247757
fit fold=1 0.014[s]
Fold 1 F1: 0.0
Training until validation scores don't improve for 10 rounds
[10]	valid_0's l2: 0.247154
Early stopping, best iteration is:
[5]	valid_0's l2: 0.246684
fit fold=2 0.004[s]
Fold 2 F1: 0.0
Training until validation scores don't improve for 10 rounds
[10]	valid_0's l2: 0.248854
Early stopping, best iteration is:
[5]	valid_0's l2: 0.248359
fit fold=3 0.004[s]
Fold 3 F1: 0.0
Training until validation scores don't improve for 10 rounds
[10]	valid_0's l2: 0.246914
Early stopping, best iteration is:
[5]	valid_0's l2: 0.2465
fit fold=4 0.004[s]
Fold 4 F1: 0.0
FINISHED | LightGBM Whole F1: 0.0000

Fitting 4 folds for each of 27 candidates, totalling 108 fits
Support Vector Machine Best parameter: {'C': 1, 'decision_function_shape': 'ovr', 'gamma': 0.1, 'kernel': 'rbf'}
----SVM train start----
fit fold=1 0.008[s]
Fold 1 F1: 42.42424242424242
fit fold=2 0.006[s]
Fold 2 F1: 66.66666666666666
fit fold=3 0.006[s]
Fold 3 F1: 62.06896551724138
fit fold=4 0.006[s]
Fold 4 F1: 47.05882352941176
FINISHED | SVM Whole F1: 55.0725

Y true:  [1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0]
XgBoost predict:  [1.   1.   0.   0.75 1.   0.25 0.5  1.   1.   0.5  0.   0.75 0.5  0.
 0.75 0.25 1.   1.   0.25 0.  ]
LightGBM predict:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
SVM predict:  [0.25 0.25 0.   0.   1.   0.   0.25 1.   1.   1.   0.   0.   0.75 0.
 0.75 0.   0.5  0.5  0.   0.  ]
